---
title: 'RAG联合推理模型：知识增强的大语言模型应用'
description: '探索检索增强生成(RAG)与大语言模型的联合推理技术，提升AI系统的知识获取和推理能力'
pubDate: '2024-01-10'
author: 'Zhang Wei'
tags: ['AI', 'RAG', 'LLM', '机器学习', '知识工程']
heroImage: "/image (1).jpg"
---


> 本文翻译整理自 [Evaluating Modular RAG with Reasoning Models](https://www.kapa.ai/blog/evaluating-modular-rag-with-reasoning-models)，版权归原作者所有。

## 目录

- [推理模型的崛起](#推理模型的崛起)
- [假设](#假设)
- [测试设置](#测试设置)
- [结果](#结果)
- [主要收获](#主要收获)
- [推理≠经验谬论](#推理经验谬论)
- [结论](#结论)

构建和维护一个强大、通用的 RAG 系统非常困难。有许多控制和参数会影响最终输出的质量，并且它们都以复杂的方式进行交互：

- **提示模板** - 决定如何引导模型生成回应
- **上下文大小** - 控制模型可以处理的信息量
- **查询扩展** - 改进原始查询以获取更相关的结果
- **分块策略** - 决定如何分割和处理文档
- **重新排序算法** - 优化检索结果的相关性排序
- **等等**

当我们对系统进行更改时，尤其是在集成新模型时，重新审视和改进这些参数对于保持良好的性能至关重要。但这也很耗时，并且需要经验才能做好。

## 推理模型的崛起

像 DeepSeek-R1 和 OpenAI 的 o3-mini 这样的新型推理模型通过内置的思维链 (CoT) 提示产生令人印象深刻的结果，在该提示中，模型旨在逐步"思考"问题，甚至在需要时进行自我纠正。据报道，这些模型在需要逻辑推理的更困难的挑战中表现更好，在这些挑战中，问题的答案是可以验证的。

> **思考题**：如果推理模型可以分解复杂的挑战并自我纠正，我们是否也可以在我们的 RAG 管道中使用它们来处理诸如查询扩展、文档检索和重新排序之类的任务？

通过构建一个信息检索工具箱并将其交给推理模型，我们或许能够构建一个更具适应性的系统，该系统可以适应变化，从而减少人工不断调整的需求。

这种范例有时被称为[模块化 RAG](https://arxiv.org/html/2407.21059v1)。在本文中，我们将分享我们最近的研究结果，这些研究涉及将标准 RAG 管道重构为基于推理模型的管道。

## 假设

探索这个想法的主要原因是为了看看它是否可以让我们简化管道并消除人工微调参数的需求。RAG 管道的核心组件是密集嵌入和文档检索。一个典型的先进 RAG 管道如下所示：

1. 接收用户的提示
2. 预处理查询以改进信息检索
3. 通过向量数据库中的相似性搜索找到相关文档
4. 重新排序结果并使用最相关的文档
5. 生成响应

![传统RAG管道架构](https://framerusercontent.com/images/gtPI3KhhkyW0HZ4ZRgClerF5Y.svg)

管道中的每个步骤都通过启发式方法进行优化，例如，过滤规则和排名调整，以优先考虑相关数据。这些硬编码的优化定义了管道的行为，但也限制了其适应性。

为了允许推理模型使用我们管道的组件，我们必须以不同的方式设置事物。我们需要将每个组件都变成模型可以调用的独立模块，而不是定义一个线性步骤序列。

![模块化RAG架构](https://framerusercontent.com/images/mn2xbxoDRfv3SFELZeAFE03uKM.svg)

在这种架构中，具有推理能力的模型可以动态地控制自己的工作流程，而不是遵循固定的管道。通过利用工具的使用，模型将确定何时以及多久运行一次完整检索或更简单的检索，以及使用什么检索参数。如果成功，这种方法可能会取代传统的 RAG 编排框架，如 LangGraph。

### 模块化系统的潜在优势

- **灵活升级** - 可以交换或升级单个模块，而无需彻底改造整个管道
- **简化调试** - 更清晰的责任划分使调试和测试更易于管理
- **模块比较** - 可以测试和替换不同的模块以比较性能
- **分布式扩展** - 模块可以针对不同的数据源进行独立扩展
- **领域特化** - 可以为特定任务或领域构建定制化模块

最后，我们想要探索的另一个用例是，这种方法是否可以帮助我们更有效地"短路"滥用或离题的查询。最难的情况通常涉及歧义，其中不清楚查询是否与产品相关。滥用查询通常是故意设计来逃避检测的。虽然更简单的情况已经可以有效地处理，但我们希望推理模型可以让我们更早地识别和退出更复杂的问题，并尽早退出。

## 测试设置

为了试用此工作流程，我们设置了一个沙盒 RAG 系统，其中包含必要的组件、静态数据和 LLM 作为评判员的评估套件。在一种配置中，我们使用了典型的固定线性管道，其中内置了硬编码的优化。

对于模块化 RAG 管道，使用 o3-mini 作为推理模型，我们在不同的策略下运行了管道的各种配置，以评估哪些效果良好，哪些效果不佳：

- **工具使用**：我们尝试让模型完全访问所有工具和整个管道，并且我们还尝试将工具使用限制为与固定线性管道结合使用的单个工具
- **提示和参数化**：我们测试了使用具有最少指令的开放式提示和高度结构化的提示。我们还尝试了各种程度的预参数化工具调用与让模型自己决定参数

对于我们运行的所有测试，我们将工具调用的次数上限设置为最多 20 次 - 对于任何给定的查询，模型只允许最多使用 20 次工具调用。我们还在中等和高推理努力下运行了所有测试：

- **中等**：较短的 CoT（思维链）步骤
- **高**：较长的 CoT 步骤，具有更详细的推理

总的来说，我们运行了 58 个不同模块化 RAG 配置的评估。

## 结果

我们的实验结果好坏参半。在某些配置中，我们观察到适度的收益，尤其是在代码生成等领域，以及在一定程度上在事实性方面。但是，与我们传统的、手动调整的工作流程相比，诸如信息检索质量和知识提取之类的关键指标基本保持不变。

贯穿我们测试的一个反复出现的主题是思维链 (CoT) 推理引入的延迟增加。虽然更深入的推理允许模型分解复杂的查询并自我纠正，但它需要迭代工具调用，从而增加了额外的时间成本。

我们发现的最大挑战是“推理 ≠ 经验”的谬论：推理模型尽管能够逐步思考，但缺乏使用检索工具的先验经验。即使有严格的提示，它也难以检索高质量的结果并区分好的和坏的输出。该模型经常犹豫不决地使用我们提供的工具，类似于我们去年使用 o1 进行的先前实验。这突出显示了一个更广泛的问题：推理模型擅长抽象问题解决，但优化工具使用而没有事先训练仍然是一个公开的挑战。

## 主要收获

- 我们的实验揭示了一个明显的“推理 ≠ 经验谬论”：推理模型并非天生就“理解”检索工具。它了解该工具做什么以及它的用途是什么，但它不知道如何使用它，人类在使用该工具后会获得的隐含知识。与传统管道不同，传统管道中的经验被编码为启发式和优化，推理模型必须被明确教导如何有效地使用工具。
- 尽管 o3-mini 能够处理更大的上下文，但我们在知识提取方面没有观察到比 4o 或 Sonnet 等模型有显着改进。简单地增加上下文大小并不是解决检索性能的灵丹妙药。
- 增加模型的推理努力只会略微提高事实准确性。我们的数据集侧重于与现实世界用例相关的技术内容，而不是数学竞赛问题或高级编码挑战。推理努力的影响可能因领域而异，对于包含更结构化或计算复杂的查询的数据集，可能会产生不同的结果。
- 模型表现出色的一个领域是代码生成，这表明推理模型可能特别适用于需要结构化、逻辑输出而不是纯粹检索的领域。

## 推理 ≠ 经验谬论

我们实验的主要收获是，推理模型自然不具备特定于工具的知识。与微调的 RAG 管道（将检索逻辑编码为预定义的步骤）不同，推理模型从一张白板开始处理每个检索调用。这会导致效率低下、犹豫不决和次优的工具使用。

为了缓解这种情况，可以想到一些可能的策略。进一步改进提示策略，即以一种为模型提供更明确指导的方式构建特定于工具的指令，可能会有所帮助。预训练或微调工具使用模型也可以使其熟悉特定的检索机制。

此外，可以考虑一种混合方法，其中预定义的启发式方法处理某些任务，而推理模型有选择地在需要时进行干预。

这些想法仍然是推测性的，但它们指出了我们可能弥合推理能力和实际工具执行之间差距的方法。

## 结论

虽然我们无法看到基于推理的模块化 RAG 相对于传统管道在我们的用例范围内有明显的优势，但该实验确实为了解其潜力和局限性提供了宝贵的见解。模块化方法的灵活性仍然具有吸引力。它允许更大的适应性、更轻松的升级以及对新模型或数据源的动态调整。

展望未来，一些有希望的技巧可用于进一步探索，包括：

- 使用不同的提示策略和预训练/微调，以提高模型理解和与检索工具交互的方式。
- 在管道的部分中使用推理模型进行战略性干预，例如用于特定用例或任务（如复杂问题回答或代码生成），而不是编排整个工作流程。

在这个阶段，像 o3-mini 这样的推理模型在合理的时间限制内，在核心检索任务方面尚未超过传统的 RAG 管道。随着模型的进步和工具使用策略的发展，基于推理的模块化 RAG 系统可能成为一种可行的替代方案，特别是对于需要动态的、逻辑密集型工作流程的领域。